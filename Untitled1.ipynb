{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed865f0c-3021-431f-bde1-2a4cb8baf4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer Type        Gender  satisfaction\n",
      "count   1.039040e+05  1.039040e+05  1.039040e+05\n",
      "mean    2.995243e-17 -3.767988e-17 -3.839792e-17\n",
      "std     1.000005e+00  1.000005e+00  1.000005e+00\n",
      "min    -4.727667e-01 -9.851920e-01 -8.744735e-01\n",
      "25%    -4.727667e-01 -9.851920e-01 -8.744735e-01\n",
      "50%    -4.727667e-01 -9.851920e-01 -8.744735e-01\n",
      "75%    -4.727667e-01  1.015031e+00  1.143545e+00\n",
      "max     2.115208e+00  1.015031e+00  1.143545e+00\n",
      "\n",
      "Number of features after preprocessing: 23\n",
      "Number of feature names: 26\n",
      "Evaluando modelo: RandomForestRegressor\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 205\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluando modelo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    204\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid[model_name], cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m--> 205\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores hiperparámetros para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejor puntuación para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\samir\\Downloads\\airline_passenger_satisfaction.csv\")\n",
    "\n",
    "# Manejo de Valores faltantes\n",
    "# Copia del DataFrame original para preservar los datos\n",
    "df_original = df.copy()\n",
    "\n",
    "# Imputación con la mediana\n",
    "median_value = df['Arrival Delay in Minutes'].median()\n",
    "df['Imputed_Median'] = df_original['Arrival Delay in Minutes'].fillna(median_value) \n",
    "\n",
    "# Codificación de la variable objetivo  \n",
    "label_encoder = LabelEncoder()  \n",
    "df['satisfaction'] = label_encoder.fit_transform(df['satisfaction'])  \n",
    "\n",
    "# Codificación de variables categóricas nominales  \n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, drop='first')  \n",
    "\n",
    "# Ajustar y transformar las variables categóricas  \n",
    "categorical_columns = ['Class', 'Type of Travel']  \n",
    "encoded_features = one_hot_encoder.fit_transform(df[categorical_columns])  \n",
    "\n",
    "# Crear DataFrame para las variables codificadas  \n",
    "encoded_df = pd.DataFrame(encoded_features, columns=one_hot_encoder.get_feature_names_out(categorical_columns))  \n",
    "\n",
    "# Concatenar los DataFrames codificados al original  \n",
    "df = pd.concat([df, encoded_df], axis=1)  \n",
    "\n",
    "# Codificación de 'Customer Type' y 'Gender'  \n",
    "df['Customer Type'] = label_encoder.fit_transform(df['Customer Type'])  \n",
    "df['Gender'] = label_encoder.fit_transform(df['Gender'])  \n",
    "\n",
    "# Eliminar las columnas originales  \n",
    "#df.drop(categorical_columns, axis=1, inplace=True)  \n",
    "# Crear una lista de columnas a eliminar excluyendo 'Imputed_NegativeOne'\n",
    "columns_to_drop = [col for col in categorical_columns if col != 'Imputed_Median']\n",
    "\n",
    "# Eliminar las columnas especificadas\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame final  \n",
    "#print(df.head(5))\n",
    "#print(df.describe())\n",
    "\n",
    "\n",
    "\n",
    "# Crear el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Seleccionar las columnas numéricas\n",
    "numeric_cols = ['Age', 'Flight Distance', 'Departure Delay in Minutes', 'Imputed_Median']\n",
    "\n",
    "# Aplicar el escalador\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "#print(df[numeric_cols].head(3))\n",
    "#print(df[numeric_cols].describe())\n",
    "\n",
    "#corr_matrix = df[numeric_cols].corr(\"spearman\")\n",
    "#sns.heatmap(corr_matrix, annot=True,cmap=\"coolwarm\")\n",
    "#plt.show()\n",
    "\n",
    "#standarización de variables categoricas \n",
    "categorical_cols=[\"Customer Type\",\"Gender\",\"satisfaction\"]\n",
    "df[categorical_cols] = scaler.fit_transform(df[categorical_cols])\n",
    "print(df[categorical_cols].describe())\n",
    "\n",
    "df['delay_index'] = df[['Departure Delay in Minutes', 'Imputed_Median']].mean(axis=1)\n",
    "\n",
    "# Print column names and data types\n",
    "#print(\"Columns in the DataFrame:\")\n",
    "#print(df.columns)\n",
    "#print(\"\\nData types:\")\n",
    "#print(df.dtypes)\n",
    "\n",
    "# Define feature groups\n",
    "ordinal_features = [\n",
    "    'Seat comfort', 'Leg room service', 'On-board service', 'Inflight service',\n",
    "    'Checkin service', 'Departure/Arrival time convenient', 'Gate location',\n",
    "    'Ease of Online booking', 'Inflight entertainment', 'Inflight wifi service',\n",
    "    'Food and drink', 'Cleanliness', 'Online boarding', 'Baggage handling'\n",
    "]\n",
    "\n",
    "# Check if all ordinal features exist in the DataFrame\n",
    "existing_ordinal_features = [feature for feature in ordinal_features if feature in df.columns]\n",
    "missing_ordinal_features = set(ordinal_features) - set(existing_ordinal_features)\n",
    "if missing_ordinal_features:\n",
    "    print(f\"Warning: The following ordinal features are missing: {missing_ordinal_features}\")\n",
    "\n",
    "# Create indices only for existing features\n",
    "df['comfort_index'] = df[['Seat comfort', 'Leg room service', 'On-board service']].mean(axis=1)\n",
    "df['service_index'] = df[['Inflight service', 'Checkin service', 'On-board service']].mean(axis=1)\n",
    "df['convenience_index'] = df[['Departure/Arrival time convenient', 'Gate location', 'Ease of Online booking']].mean(axis=1)\n",
    "df['entertainment_index'] = df[['Inflight entertainment', 'Inflight wifi service']].mean(axis=1)\n",
    "df['food_index'] = df['Food and drink']\n",
    "df['cleanliness_index'] = df['Cleanliness']\n",
    "\n",
    "index_features = [\n",
    "    'comfort_index', 'service_index', 'convenience_index', 'entertainment_index',\n",
    "    'food_index', 'cleanliness_index'\n",
    "]\n",
    "\n",
    "# Updated categorical features based on the new column names\n",
    "categorical_features = ['Class_Eco', 'Class_Eco Plus', 'Type of Travel_Personal Travel']\n",
    "\n",
    "# Check for the updated categorical feature columns\n",
    "existing_categorical_features = [feature for feature in categorical_features if feature in df.columns]\n",
    "missing_categorical_features = set(categorical_features) - set(existing_categorical_features)\n",
    "if missing_categorical_features:\n",
    "    print(f\"Warning: The following categorical features are missing: {missing_categorical_features}\")\n",
    "\n",
    "# Assuming these are your LabelEncoded features that are already standardized\n",
    "label_encoded_features = ['Customer Type', 'Gender', 'satisfaction']\n",
    "\n",
    "# Check if all label_encoded_features exist in the DataFrame\n",
    "existing_label_encoded_features = [feature for feature in label_encoded_features if feature in df.columns]\n",
    "missing_label_encoded_features = set(label_encoded_features) - set(existing_label_encoded_features)\n",
    "if missing_label_encoded_features:\n",
    "    print(f\"Warning: The following label-encoded features are missing: {missing_label_encoded_features}\")\n",
    "\n",
    "# Create preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), existing_ordinal_features + index_features),\n",
    "        ('cat', 'passthrough', existing_categorical_features)  # We use 'passthrough' since these are already one-hot encoded\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit and transform the data\n",
    "X = df[existing_ordinal_features + index_features + existing_categorical_features + existing_label_encoded_features]\n",
    "y = df['satisfaction'] if 'satisfaction' in df.columns else None\n",
    "\n",
    "if y is None:\n",
    "    print(\"Error: 'satisfaction' column is missing. Cannot proceed with the analysis.\")\n",
    "else:\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = existing_ordinal_features + index_features + existing_categorical_features + existing_label_encoded_features\n",
    "\n",
    "    print(\"\\nNumber of features after preprocessing:\", X_processed.shape[1])\n",
    "    print(\"Number of feature names:\", len(feature_names))\n",
    "\n",
    "\n",
    "\n",
    "# Crear una función para evaluar los modelos\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Define los modelos como un diccionario\n",
    "models = {\n",
    "    'RandomForestRegressor': RandomForestRegressor(random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'MLPRegressor': MLPRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Define la cuadrícula de hiperparámetros\n",
    "param_grid = {\n",
    "    'RandomForestRegressor': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 5, 10],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'liblinear']\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'hidden_layer_sizes': [(50,), (100,)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ajuste de hiperparámetros y evaluación\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluando modelo: {model_name}\")\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid[model_name], cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"Mejores hiperparámetros para {model_name}: {grid.best_params_}\")\n",
    "    print(f\"Mejor puntuación para {model_name}: {grid.best_score_}\")\n",
    "\n",
    "\n",
    "\n",
    "# Feature selection (optional)\n",
    "selector = SelectFromModel(best_model, prefit=True)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "\n",
    "# Train the final model with selected features (optional)\n",
    "final_model = best_model\n",
    "final_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate the final model (optional)\n",
    "evaluate_model(final_model, X_test_selected, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019186a1-197d-433d-bece-f67dceefac3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (g6)",
   "language": "python",
   "name": "g6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
